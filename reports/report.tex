\documentclass[a4paper,11pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[ngerman]{babel}
\usepackage{graphicx}
\usepackage{array}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{float}

\usepackage[scaled]{helvet}
\renewcommand{\familydefault}{\sfdefault}

\usepackage[a4paper, top=2cm, bottom=2cm, left=2cm, right=2cm]{geometry}

\usepackage{setspace}
\setstretch{1.5}

\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt}

\usepackage{microtype}
\sloppy
\hyphenpenalty=1000
\tolerance=3000

\renewcommand{\footnotesize}{\fontsize{10}{12}\selectfont}

\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}

\usepackage{titlesec}
\titleformat{\section}{\normalfont\fontsize{12}{14}\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\normalfont\fontsize{12}{14}\bfseries}{\thesubsection}{1em}{}
\titleformat{\subsubsection}{\normalfont\fontsize{12}{14}\bfseries}{\thesubsubsection}{1em}{}

\usepackage[
  colorlinks=true,
  linkcolor=black,
  citecolor=blue,
  filecolor=black,
  urlcolor=blue
]{hyperref}
\usepackage[capitalise,nameinlink]{cleveref}

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0pt}
\fancyfoot[C]{\thepage}

\usepackage[backend=biber, style=apa]{biblatex}
\addbibresource{references.bib}

\usepackage{titling}

\usepackage{acronym}
\usepackage[german=quotes]{csquotes}

\usepackage{caption}
\usepackage{threeparttable}
\captionsetup[table]{
    font=small,
    skip=10pt,
    labelfont=bf
}

\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}
\lstset{style=mystyle}

\begin{document}

\begin{titlepage}
    \thispagestyle{empty}
    \centering
    \vspace*{5cm}
    {\Huge\bfseries Projekt: Edge AI DLBAIPEAI01\_D \par}
    \vspace{1cm}
    {\Large Fallstudie \par}
    \vspace{0.5cm}
    {\large Studiengang: Angewandte Künstliche Intelligenz \par}
    \vspace{0.5cm}
    {\large Sven Behrens \par}
    \vspace{0.5cm}
    {\large Matrikelnummer: 42303511 \par}
    \vspace{0.5cm}
    {\large Prof. Dr. Bertram Taetz \par}
    \vspace{0.5cm}
    {\large \today \par}
\end{titlepage}

\pagenumbering{Roman}
\setcounter{page}{1}

\tableofcontents
\newpage

\listoffigures
\addcontentsline{toc}{section}{Abbildungsverzeichnis}
\newpage

\listoftables
\addcontentsline{toc}{section}{Tabellenverzeichnis}
\newpage

\section*{Abkürzungsverzeichnis}
\addcontentsline{toc}{section}{Abkürzungsverzeichnis}
\begin{acronym}[ONNX]
    \acro{GRU}{Gated Recurrent Unit}
    \acro{MAE}{Mean Absolute Error}
    \acro{ONNX}{Open Neural Network Exchange}
    \acro{RMSE}{Root Mean Squared Error}
    \acro{WHO}{World Health Organization}
\end{acronym}
\newpage

\pagenumbering{arabic}
\setcounter{page}{1}

\section{Einleitung}
Die Luftqualität in städtischen Gebieten stellt ein wachsendes Gesundheitsrisiko dar. Insbesondere
Feinstaub (PM2.5) und Stickstoffdioxid (NO2) werden mit Atemwegserkrankungen, Herz-Kreislauf-Beschwerden
und einer erhöhten Mortalität in Verbindung gebracht \parencite{who2016airpollution, lelieveld2021luftverschmutzung}. Besonders gefährdet sind vulnerable Gruppen wie
Kinder, ältere Menschen und Personen mit Vorerkrankungen \parencite{eea2023children}. An stark befahrenen Straßen in der Nähe von
Schulen und Wohngebieten können die Schadstoffkonzentrationen kurzfristig kritische Werte erreichen,
ohne dass rechtzeitig Gegenmaßnahmen eingeleitet werden.

Klassische Umweltüberwachungssysteme erfassen zwar kontinuierlich Messdaten, leiten daraus jedoch keine
unmittelbaren Handlungsempfehlungen ab. Die Daten werden zentral gesammelt und erst mit Verzögerung
ausgewertet. Für zeitkritische Anwendungen wie die dynamische Verkehrssteuerung bei Schadstoffspitzen
ist dieser Ansatz unzureichend. Edge AI bietet hier einen vielversprechenden Lösungsansatz: Durch die
lokale Ausführung von Vorhersagemodellen direkt an der Messstation können Prognosen in Echtzeit erstellt
und Maßnahmen ohne Umweg über zentrale Server ausgelöst werden.

Vor diesem Hintergrund wurde im Rahmen des Moduls \enquote{Projekt: Edge AI} an der IU Internationalen
Hochschule ein System entwickelt, das die Luftqualität an der Messstation Hamburg Habichtstraße
vorhersagt. Die Station befindet sich an einer stark befahrenen Straße in unmittelbarer Nähe einer
Schule und eignet sich daher besonders als Anwendungsfall. Das System prognostiziert sowohl die
PM2.5- als auch die NO2-Konzentration eine Stunde im Voraus und leitet daraus ein dreistufiges
Ampelsystem ab, das bei erhöhter Belastung automatisch Verkehrsmaßnahmen wie Geschwindigkeitsbegrenzungen
oder Umleitungen auslösen kann.

Die methodische Vorgehensweise umfasst mehrere aufeinander aufbauende Schritte. Zunächst werden
stündliche Messdaten der OpenAQ-Plattform vorverarbeitet und durch Feature Engineering angereichert.
Anschließend werden vier Modelltypen, lineare Regression, Random Forest, Gradient Boosting und
\ac{GRU}, trainiert und verglichen. Durch eine systematische Feature-Importance-Analyse wird das
Feature-Set von 28 auf 17 Merkmale reduziert. Die besten Modelle werden in das \ac{ONNX}-Format
exportiert und hinsichtlich Inferenzzeit und Modellgröße für den Edge-Einsatz evaluiert. Abschließend
wird eine Edge-Inference-Pipeline implementiert, die den gesamten Ablauf von der Sensorablesung
bis zur Ampelentscheidung abbildet.

Das vorliegende Projekt gliedert sich wie folgt: Nach der Beschreibung der Projektumgebung und
der Datengrundlage werden die Vorverarbeitung und das Modelltraining erläutert. Anschließend werden
die Edge-Optimierung, das Alert-System und die Inference-Pipeline vorgestellt. Abschließend werden
die Ergebnisse kritisch reflektiert und Verbesserungspotenziale aufgezeigt.

\section{Hauptteil}
\subsection{Projektumgebung}
Zu Beginn des Projekts wurde ein GitHub-Repository\footnote{\url{https://github.com/svenb23/EdgeAI}}
angelegt, um eine nachvollziehbare Versionsverwaltung zu gewährleisten. Als Implementierungssprache
wurde Python gewählt. Für die Reproduzierbarkeit wurde eine virtuelle Umgebung mit \texttt{venv}
eingerichtet, in der alle Abhängigkeiten über eine \texttt{requirements.txt} installiert werden.
Zu den zentralen Bibliotheken zählen \texttt{pandas} und \texttt{numpy} für die Datenverarbeitung,
\texttt{scikit-learn} für die klassischen Machine-Learning-Modelle, \texttt{torch} (CPU-Version)
sowie \texttt{onnxruntime} und \texttt{skl2onnx} für den \ac{ONNX}-Export und die Edge-Inferenz.

Die gesamte Pipeline, von den Rohdaten bis zur Edge-Inference-Demo, lässt sich mit einem
einzigen Befehl (\texttt{python run\_all.py}) ausführen. Das Skript ruft alle Verarbeitungsschritte
sequenziell auf und stellt sicher, dass jedes Teilskript im korrekten Arbeitsverzeichnis
ausgeführt wird. Dadurch kann ein Tutor die Ergebnisse ohne manuelle Konfiguration reproduzieren.

\subsection{Datengrundlage}
Für das Training und die Evaluation der Modelle werden reale Luftqualitätsdaten benötigt.
Im Vorfeld wurden drei Datenquellen evaluiert: das UCI Air Quality Dataset
\parencite{devito2016uci} (globale Stadte), das Umweltbundesamt
\parencite{uba2025luft} (zuverlässig, aber manueller Download) und die OpenAQ-Plattform
\parencite{openaq2025} (globale API mit deutschen Stationen). Die Wahl fiel auf OpenAQ, da die
Plattform einen automatisierten API-Zugang bietet und die Aufgabenstellung diese Quelle
explizit als Beispiel nennt.

Als Messstation wurde zunächst Hamburg Max-Brauer-Allee~II (Straßenstation) in Betracht
gezogen. Eine Datenanalyse ergab jedoch, dass für PM2.5 lediglich 486 Datenpunkte aus dem
Dezember 2025 vorlagen, während PM10, NO2 und CO über alle zwölf Monate hinweg knapp 8\,000
Messpunkte aufwiesen. Da ein vollständiges Jahr für die Abbildung saisonaler Muster notwendig
ist, wurde stattdessen die Station Hamburg Habichtstraße (OpenAQ Location~ID~3010) gewählt.
Diese Straßenstation befindet sich in unmittelbarer Nähe einer Schule und liefert für alle
vier Parameter, PM2.5, PM10, NO2 und CO, jeweils rund 7\,900 stündliche Messwerte
über das gesamte Jahr 2025.

Der Datenabruf erfolgt über ein Python-Skript (\texttt{download\_openaq.py}), das die
OpenAQ~v3-API monatsweise abfragt und die Ergebnisse als CSV im Long-Format speichert.
Die monatsweise Paginierung ist notwendig, um die API-Limits von 1\,000 Datensätzen pro
Anfrage einzuhalten. Das resultierende Rohdatenfile enthält rund 31\,500 Messungen
mit den Spalten \texttt{parameter}, \texttt{value}, \texttt{datetime\_utc} und
\texttt{datetime\_local}.

\subsection{Datenvorverarbeitung}
Die Vorverarbeitung erfolgt in fünf aufeinander aufbauenden Schritten, die jeweils das Ergebnis
des vorherigen Schritts einlesen und um neue Merkmale ergänzen.

Im ersten Schritt wird das Rohdatenfile vom Long-Format (eine Zeile pro Messung) in ein
Wide-Format (eine Zeile pro Stunde, eine Spalte pro Schadstoff) überführt. Fehlende Werte
werden linear interpoliert, wobei Lücken von maximal sechs Stunden geschlossen werden.
Verbleibende Lücken werden entfernt.

Der zweite Schritt erzeugt zwölf zeitbasierte Merkmale. Neben den Rohwerten für Stunde,
Wochentag und Monat werden binäre Indikatoren für Wochenende und Berufsverkehr (7--9 und
16--18~Uhr) erstellt. Zusätzlich werden Stunde, Monat und Wochentag zyklisch als Sinus-
und Kosinuswerte kodiert, um die Periodizität für die Modelle abzubilden.

Im dritten Schritt werden sechs Lag-Features erzeugt, die die Schadstoffwerte der
vorangegangenen Stunden als Prädiktoren bereitstellen. Für PM2.5 werden drei Lags
(1h, 2h, 3h) erstellt, für NO2, CO und PM10 jeweils ein Lag von einer Stunde.

Der vierte Schritt berechnet gleitende Statistiken über verschiedene Zeitfenster. Für
PM2.5 werden die rollierenden Mittelwerte über 3, 6 und 24~Stunden sowie die rollierende
Standardabweichung über 3~Stunden berechnet. Diese vier Features erfassen lokale Trends
und die kurzfristige Variabilität der Feinstaubkonzentration.

Im fünften Schritt werden drei schadstoffübergreifende Merkmale ergänzt: das Verhältnis
PM2.5/PM10 als Indikator für den Anteil von Verbrennungspartikeln am Gesamtfeinstaub sowie
die stündliche und dreistündliche Änderungsrate von PM2.5 ($\Delta$1h, $\Delta$3h).

Nach Abschluss aller fünf Schritte umfasst der Datensatz die vier Rohwerte sowie 25
engineerte Merkmale, insgesamt also 29~Spalten. Durch die Lag- und Rolling-Berechnungen
gehen die ersten 23~Datenpunkte verloren, sodass der finale Datensatz rund 7\,850 stündliche
Beobachtungen enthält.

\subsection{Modelltraining}
\subsubsection{Train/Test-Split}
Für die Aufteilung des Datensatzes wird ein chronologischer 80/20-Split verwendet. Im Gegensatz
zu einem zufälligen Split bewahrt diese Strategie die zeitliche Reihenfolge der Messdaten und
verhindert Data Leakage, da das Modell ausschließlich auf vergangenen Daten trainiert und auf
zukünftigen Daten evaluiert wird. Die ersten 80\,\% der Beobachtungen (ca. 6\,280 Stunden)
bilden den Trainingssatz, die letzten 20\,\% (ca. 1\,570 Stunden) den Testsatz.

Als Zielvariablen werden die PM2.5- und die NO2-Konzentration jeweils eine Stunde in die
Zukunft verschoben. Der Wert von \texttt{target\_pm25\_1h} zum Zeitpunkt $t$ entspricht somit
dem tatsächlichen PM2.5-Wert zum Zeitpunkt $t+1$. Analog wird \texttt{target\_no2\_1h}
gebildet. Durch diese Verschiebung lernen die Modelle, aus den aktuellen Messwerten und den
engineerten Merkmalen die Schadstoffbelastung der nächsten Stunde vorherzusagen. Die letzte
Zeile des Datensatzes, für die kein Zielwert existiert, wird entfernt. Als Eingabemerkmale
dienen alle 28~Features aus der Vorverarbeitung.

\subsubsection{PM2.5-Modelle}
Für die Vorhersage der PM2.5-Konzentration werden vier Modelltypen trainiert, die sich in
Komplexität und Modellierungsansatz unterscheiden.

Die lineare Regression dient als Baseline-Modell. Sie wird ohne weitere
Hyperparameter mit den Standardeinstellungen von scikit-learn trainiert und liefert einen
ersten Referenzwert für die erreichbare Vorhersagegenauigkeit.

Das Random-Forest-Modell verwendet 100~Entscheidungsbäume mit einer maximalen
Tiefe von~15. Durch die Begrenzung der Baumtiefe wird Overfitting reduziert, während die
Ensemble-Methode dennoch nichtlineare Zusammenhänge erfassen kann. Die Berechnung erfolgt
parallelisiert über alle verfügbaren CPU-Kerne.

Das Gradient-Boosting-Modell baut sequenziell 200~Bäume mit einer maximalen
Tiefe von~5 und einer Lernrate von~0,1 auf. Die geringere Baumtiefe im Vergleich zum
Random Forest kompensiert das Boosting-Verfahren durch die höhere Anzahl an Iterationen.
Die Lernrate steuert den Beitrag jedes einzelnen Baumes zum Gesamtmodell.

Das \ac{GRU}-Netzwerk ist das einzige sequenzielle Modell im Vergleich. Es verarbeitet
Eingabesequenzen von sechs aufeinanderfolgenden Stunden, um die Konzentration der siebten
Stunde vorherzusagen. Die Architektur besteht aus einer \ac{GRU}-Schicht mit 32~Hidden Units,
gefolgt von einer linearen Ausgabeschicht. Vor dem Training werden alle Features mit einem
StandardScaler normalisiert. Das Modell wird über 30~Epochen mit dem Adam-Optimizer
(Lernrate~0,001) und einer Batch-Größe von~64 trainiert. Als Verlustfunktion wird der
Mean Squared Error verwendet.

Alle vier Modelle werden auf dem Testsatz anhand von \ac{MAE}, \ac{RMSE} und $R^2$ evaluiert.
Die klassischen Modelle werden als Pickle-Dateien gespeichert, das \ac{GRU}-Modell als
PyTorch-State-Dict zusammen mit dem zugehörigen Scaler.

\subsubsection{NO2-Modelle}
Für die Vorhersage der NO2-Konzentration werden dieselben vier Modellarchitekturen mit
identischen Hyperparametern trainiert. Das Eingabe-Feature-Set bleibt unverändert bei
28~Merkmalen, lediglich die Zielvariable wechselt von \texttt{target\_pm25\_1h} zu
\texttt{target\_no2\_1h}. Diese einheitliche Konfiguration ermöglicht einen direkten
Vergleich der Modellleistung zwischen beiden Schadstoffen und zeigt, wie gut die
PM2.5-orientierten Lag- und Rolling-Features auch für die NO2-Vorhersage geeignet sind.

\subsection{Feature Importance und Feature-Reduktion}
Um das Feature-Set für den Edge-Einsatz zu reduzieren, wird eine systematische
Feature-Importance-Analyse durchgeführt. Dabei kommen vier Methoden zum Einsatz: die
absolute Pearson-Korrelation mit der jeweiligen Zielvariable, die Mean Decrease in Impurity
(MDI) des Random-Forest-Modells, die MDI des Gradient-Boosting-Modells sowie die
Permutation Importance auf dem Testsatz (zehn Wiederholungen, Gradient-Boosting-Modell).
Jede Methode erzeugt ein Ranking der 28~Features von~1 (wichtigstes) bis~28 (unwichtigstes).
Aus den vier Einzelrankings wird der Durchschnittsrang berechnet
(siehe \cref{tab:feature_importance_pm25} im Anhang).

Für PM2.5 dominieren die physikalisch-chemischen Merkmale: Der aktuelle PM2.5-Wert
(Durchschnittsrang~1,0), die stündliche Änderungsrate (6,5), der 24-Stunden-Mittelwert (6,75)
und der erste Lag (6,75) belegen die vorderen Plätze. Die elf zeitbasierten Features
(Stunde, Wochentag, Monat jeweils als Rohwert sowie Sinus- und Kosinuskodierung, dazu die
binären Indikatoren für Wochenende und Berufsverkehr) weisen durchweg Durchschnittsränge
von~19 oder höher auf und tragen kaum zur Vorhersage bei.

Für NO2 ergibt sich ein differenzierteres Bild. Der aktuelle NO2-Wert (Rang~1,0) und der
zugehörige Lag (3,0) sind erwartungsgemäß dominant. Einige zeitbasierte Features wie der
Kosinus der Stunde (3,75) erreichen hier deutlich höhere Ränge als bei PM2.5, was auf
ausgeprägtere tageszeitliche Muster der NO2-Konzentration hindeutet. Dennoch wird für
beide Schadstoffe dasselbe reduzierte Feature-Set verwendet, um auf dem Edge-Gerät eine
einheitliche Feature-Berechnung zu ermöglichen.

Die Reduktion von 28 auf 17~Features (39\,\% Reduktion) entfernt ausschließlich die elf
zeitbasierten Merkmale. Das reduzierte Set umfasst die vier Rohwerte (PM2.5, PM10, NO2, CO),
sechs Lag-Features, vier Rolling-Statistiken sowie drei schadstoffübergreifende Merkmale.
Anschließend werden alle vier Modelle für beide Schadstoffe mit dem reduzierten Feature-Set
neu trainiert und mit den Baseline-Ergebnissen (28~Features) verglichen
(siehe \cref{tab:reduced_pm25,tab:reduced_no2} im Anhang).

Für PM2.5 zeigt der Vergleich, dass die Feature-Reduktion die Vorhersagequalität nicht
verschlechtert. Die lineare Regression verbessert sich sogar leicht (MAE~0,914 statt~0,929),
und auch das \ac{GRU}-Netzwerk profitiert deutlich von der Reduktion (MAE~1,544 statt~1,743).
Dies deutet darauf hin, dass die entfernten zeitbasierten Features für PM2.5 eher Rauschen
als Information beigetragen haben.

Für NO2 zeigt sich hingegen eine leichte Verschlechterung, da die tageszeitlichen
Features hier relevanter sind. Der MAE der linearen Regression steigt von~4,019 auf~4,199,
der des Random Forest von~3,903 auf~4,223. Die Einbußen bleiben jedoch moderat und
rechtfertigen den Vorteil eines einheitlichen, schlankeren Feature-Sets für den Edge-Einsatz.

\subsection{Edge-Optimierung}
\subsubsection{ONNX-Export}
Für den Edge-Einsatz werden die besten Modelle in das \ac{ONNX}-Format exportiert. Da die
lineare Regression bei PM2.5 das beste Ergebnis liefert und gleichzeitig die geringste
Komplexität aufweist, wird sie für beide Zielvariablen als Edge-Modell gewählt. Der Export
erfolgt mit der Bibliothek \texttt{skl2onnx}, die scikit-learn-Modelle direkt in
\ac{ONNX}-Graphen überführt. Die Eingabe wird als Float-Tensor mit 17~Features definiert.
Nach dem Export wird jedes Modell mit \texttt{onnxruntime} verifiziert, indem die Vorhersagen
auf dem Testsatz mit den Ergebnissen des Originalmodells verglichen werden. Beide Modelle
erreichen identische MAE-Werte (PM2.5: 0,914; NO2: 4,199) und bestätigen damit die
korrekte Konvertierung.

\subsubsection{Benchmark}
Die exportierten \ac{ONNX}-Modelle werden hinsichtlich Modellgröße und Inferenzzeit evaluiert.
Beide Modelle belegen jeweils nur 0,3~KB Speicherplatz, was selbst für stark
speicherbeschränkte Mikrocontroller geeignet ist. Die Inferenzzeit wird über 100~Durchläufe
gemittelt. Eine einzelne Vorhersage benötigt unter 0,02~ms, eine Batch-Inferenz über den
gesamten Testsatz (ca. 1\,570 Datenpunkte) unter 0,1~ms. Diese Werte liegen weit unter den
Anforderungen einer stündlichen Vorhersage und belegen die Echtzeitfähigkeit des Systems.

\subsection{Alert-System}
Aus den Vorhersagen beider Schadstoffe wird ein dreistufiges Ampelsystem abgeleitet, das
als Entscheidungsgrundlage für Verkehrsmaßnahmen dient. Die Schwellenwerte orientieren sich
an den Richtwerten der \ac{WHO}: Für PM2.5 liegt der 24-Stunden-Richtwert bei
15\,\textmu g/m\textsuperscript{3}, für NO2 der 24-Stunden-Richtwert bei
25\,\textmu g/m\textsuperscript{3} \parencite{who2021aqg}.

Die drei Eskalationsstufen sind wie folgt definiert: Grün (PM2.5~$<$~15 und NO2~$<$~40)
bedeutet Normalbetrieb ohne Einschränkungen. Gelb (PM2.5 zwischen 15 und 25 oder NO2
zwischen 40 und 80) löst eine Geschwindigkeitsbegrenzung auf 30\,km/h aus. Rot
(PM2.5~$>$~25 oder NO2~$>$~80) führt zu einer Umleitung des Verkehrs. Die Bewertung
erfolgt nach dem Worst-Case-Prinzip: Sobald einer der beiden Schadstoffe eine höhere
Stufe erreicht, wird die gesamte Bewertung auf diese Stufe angehoben.

Dieses kombinierte System stellt sicher, dass auch dann Maßnahmen ergriffen werden, wenn
nur ein Schadstoff erhöhte Werte aufweist, während der andere unauffällig bleibt.

\subsection{Edge-Inference-Pipeline}
Die Edge-Inference-Pipeline bildet den gesamten Ablauf von der Sensorablesung bis zur
Ampelentscheidung ab und simuliert damit den Betrieb auf einem Edge-Gerät. Die zentrale
Komponente ist die Klasse \texttt{EdgeInference}, die beide \ac{ONNX}-Modelle (PM2.5 und
NO2) lädt und über die Methode \texttt{add\_reading} neue Messwerte entgegennimmt.

Intern verwaltet die Klasse einen Ringpuffer von 24~Stunden, der für die Berechnung des
längsten Rolling-Features (pm25\_roll\_mean\_24h) benötigt wird. Erst wenn der Puffer
vollständig gefüllt ist, werden Vorhersagen erzeugt. Bei jedem neuen Messwert berechnet
die Methode \texttt{\_compute\_features} die 17~reduzierten Features direkt aus dem Puffer:
aktuelle Rohwerte, Lag-Features aus den vorherigen Einträgen, Rolling-Mittelwerte und
Standardabweichungen über die letzten 3, 6 bzw. 24~Werte sowie das PM2.5/PM10-Verhältnis
und die Änderungsraten.

Der resultierende Feature-Vektor wird an beide \ac{ONNX}-Sessions übergeben, die jeweils
die Konzentration eine Stunde im Voraus prognostizieren. Aus den beiden Vorhersagen leitet
die Methode \texttt{\_classify} nach dem im vorherigen Abschnitt beschriebenen
Worst-Case-Prinzip die Ampelstufe ab. Das Ergebnis enthält die vorhergesagten Werte für
PM2.5 und NO2 sowie die zugehörige Alarmstufe (Grün, Gelb oder Rot).

In der Demo-Ausführung wird die Pipeline mit den realen Testdaten gespeist, indem jede
Stunde sequenziell als Sensormessung übergeben wird. Die Ausgabe zeigt die Verteilung
der Alarmstufen sowie die letzten Übergänge zwischen den Stufen.

\section{Fazit}
\subsection{Zielerreichung und Projektergebnisse}
% TODO

\subsection{Kritische Reflexion}
% TODO

\subsection{Verbesserungspotenziale}
% TODO

\subsection{Ausblick}

\section*{Projektrepository}
\addcontentsline{toc}{section}{Projektrepository}
Der vollständige Quellcode ist im GitHub-Repository verfügbar: \url{https://github.com/svenb23/EdgeAI}

\newpage

\printbibliography
\addcontentsline{toc}{section}{Literaturverzeichnis}

\newpage
\section*{Verzeichnis der Anhänge}
\addcontentsline{toc}{section}{Verzeichnis der Anhänge}

\appendix
\section*{Anhang}
\addcontentsline{toc}{section}{Anhang}

\begin{table}[H]
\centering
\caption{Feature-Importance-Ranking für PM2.5 (Durchschnittsrang aus vier Methoden)}
\label{tab:feature_importance_pm25}
\small
\begin{tabular}{@{}llccccr@{}}
\toprule
Rang & Feature & Korr. & RF MDI & GB MDI & Perm. & {\O} Rang \\
\midrule
1  & pm25                & 1  & 1  & 1  & 1  & 1,00 \\
2  & pm25\_diff\_1h      & 20 & 2  & 2  & 2  & 6,50 \\
3  & pm25\_roll\_mean\_24h & 9  & 3  & 3  & 12 & 6,75 \\
4  & pm25\_lag\_1        & 3  & 5  & 16 & 3  & 6,75 \\
5  & pm25\_roll\_mean\_3h & 2  & 4  & 14 & 7  & 6,75 \\
6  & pm10\_lag\_1        & 8  & 7  & 10 & 5  & 7,50 \\
7  & pm25\_roll\_mean\_6h & 4  & 14 & 4  & 11 & 8,25 \\
8  & pm10               & 7  & 12 & 12 & 4  & 8,75 \\
9  & co                 & 11 & 9  & 9  & 8  & 9,25 \\
10 & pm25\_roll\_std\_3h & 15 & 8  & 6  & 10 & 9,75 \\
11 & no2                & 17 & 6  & 5  & 14 & 10,50 \\
12 & pm25\_lag\_2        & 5  & 16 & 15 & 6  & 10,50 \\
13 & pm25\_pm10\_ratio   & 10 & 11 & 7  & 15 & 10,75 \\
14 & co\_lag\_1          & 12 & 13 & 11 & 9  & 11,25 \\
15 & pm25\_diff\_3h      & 19 & 10 & 8  & 13 & 12,50 \\
16 & no2\_lag\_1         & 18 & 15 & 13 & 18 & 16,00 \\
17 & pm25\_lag\_3        & 6  & 20 & 22 & 21 & 17,25 \\
\midrule
18 & hour\_cos           & 25 & 17 & 17 & 17 & 19,00 \\
19 & hour               & 27 & 19 & 18 & 16 & 20,00 \\
20 & hour\_sin           & 24 & 18 & 20 & 19 & 20,25 \\
21 & month\_sin          & 13 & 23 & 23 & 23 & 20,50 \\
22 & month              & 14 & 22 & 21 & 25 & 20,50 \\
23 & dow\_sin            & 22 & 21 & 19 & 20 & 20,50 \\
24 & month\_cos          & 16 & 24 & 24 & 27 & 22,75 \\
25 & day\_of\_week       & 21 & 25 & 26 & 22 & 23,50 \\
26 & dow\_cos            & 23 & 26 & 25 & 28 & 25,50 \\
27 & is\_rushhour        & 28 & 27 & 27 & 24 & 26,50 \\
28 & is\_weekend         & 26 & 28 & 28 & 26 & 27,00 \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item Korr. = Absolute Pearson-Korrelation, RF MDI = Random Forest Mean Decrease in Impurity,
GB MDI = Gradient Boosting MDI, Perm. = Permutation Importance.
Die oberen 17~Features (über dem Strich) bilden das reduzierte Feature-Set.
\end{tablenotes}
\end{table}

\begin{table}[H]
\centering
\caption{Modellvergleich PM2.5: Baseline (28~Features) vs. reduziertes Set (17~Features)}
\label{tab:reduced_pm25}
\small
\begin{tabular}{@{}l rr r rr r rr r@{}}
\toprule
 & \multicolumn{3}{c}{MAE} & \multicolumn{3}{c}{RMSE} & \multicolumn{3}{c}{$R^2$} \\
\cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10}
Modell & 28 & 17 & Diff. & 28 & 17 & Diff. & 28 & 17 & Diff. \\
\midrule
Linear Regression  & 0,929 & 0,914 & $-$0,015 & 1,537 & 1,529 & $-$0,008 & 0,930 & 0,931 & $+$0,001 \\
Random Forest      & 0,981 & 0,977 & $-$0,004 & 1,578 & 1,581 & $+$0,003 & 0,926 & 0,926 & $\pm$0,000 \\
Gradient Boosting  & 0,990 & 0,975 & $-$0,015 & 1,579 & 1,634 & $+$0,055 & 0,926 & 0,921 & $-$0,005 \\
GRU                & 1,743 & 1,544 & $-$0,199 & 2,493 & 2,302 & $-$0,191 & 0,817 & 0,844 & $+$0,027 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Modellvergleich NO2: Baseline (28~Features) vs. reduziertes Set (17~Features)}
\label{tab:reduced_no2}
\small
\begin{tabular}{@{}l rr r rr r rr r@{}}
\toprule
 & \multicolumn{3}{c}{MAE} & \multicolumn{3}{c}{RMSE} & \multicolumn{3}{c}{$R^2$} \\
\cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10}
Modell & 28 & 17 & Diff. & 28 & 17 & Diff. & 28 & 17 & Diff. \\
\midrule
Linear Regression  & 4,019 & 4,199 & $+$0,180 & 5,394 & 5,604 & $+$0,210 & 0,880 & 0,871 & $-$0,009 \\
Random Forest      & 3,903 & 4,223 & $+$0,320 & 5,200 & 5,648 & $+$0,448 & 0,889 & 0,869 & $-$0,020 \\
Gradient Boosting  & 4,015 & 4,285 & $+$0,270 & 5,368 & 5,757 & $+$0,389 & 0,881 & 0,864 & $-$0,018 \\
GRU                & 5,989 & 6,756 & $+$0,767 & 7,824 & 8,819 & $+$0,995 & 0,749 & 0,681 & $-$0,068 \\
\bottomrule
\end{tabular}
\end{table}

\end{document}
